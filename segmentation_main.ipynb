{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cbInL1b5zcdL"
      },
      "source": [
        "# AI in Medicine I - Practical 2: Brain Tissue Segmentation\n",
        "\n",
        "Segmentation of different tissues from MRI scans of the brain is an important step for further downstream applications such as disease prediction, classification or brain age estimation.\n",
        "\n",
        "The goal of the coursework is to implement classical and deep learning approaches for segmentation of different tissue types in MRI scans of the brain, i.e., background, cerebrospinal fluid (CSF), white matter (WM), and gray matter (GM). We provide data from a total of 652 healthy subjects, that is split into different development sets and a hold-out test set on which you will evaluate your final segmentation accuracy.\n",
        "Each approach will require a processing pipeline with different components that you will need to implement using methods that were discussed in the lectures and tutorials. There are three dedicated parts in the Jupyter notebook for each approach which contain some detailed instructions and some helper code.\n",
        "\n",
        "**Make sure to select the correct runtime when working in Google Colab (GPU)**\n",
        "\n",
        "### Read the text descriptions and code cells carefully and look out for the cells marked with 'TASK', 'ADD YOUR CODE HERE', and 'QUESTION'."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nbfzqO-Bzcdb"
      },
      "outputs": [],
      "source": [
        "# Only run this cell when in Google Colab\n",
        "! git init\n",
        "! git remote add origin https://github.com/compai-lab/aim-practical-2-brain-segmentation.git\n",
        "! git fetch\n",
        "! git checkout -t origin/main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIYx1Gg0zcdf"
      },
      "source": [
        "## Downloading the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8j056FEazcdg"
      },
      "outputs": [],
      "source": [
        "! wget -q --show-progress https://www.dropbox.com/s/w9njau9t6rrheel/brainage-data.zip\n",
        "! unzip -qq -o brainage-data.zip\n",
        "! wget -q --show-progress https://www.dropbox.com/s/f5mt8p9pkszff3x/brainage-testdata.zip\n",
        "! unzip -qq -o brainage-testdata.zip"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T8erjk2Tzcdh"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6HhMfnFBzcdi"
      },
      "outputs": [],
      "source": [
        "from argparse import Namespace\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nibabel as nib\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import torch\n",
        "from torch import Tensor\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import glob\n",
        "\n",
        "from data_utils import load_nii, load_segmentations\n",
        "from plot_utils import plot_segmentations\n",
        "from utils import seed_everything, TensorboardLogger\n",
        "%load_ext tensorboard\n",
        "%load_ext autoreload\n",
        "%autoreload 2"
      ]
    },
    
     {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5D_ox6Lzcdk"
      },
      "source": [
        "## Getting started and familiarise ourselves with the data\n",
        "\n",
        "We provide the data of 652 subjects from which we use 522 for training, 65 for validation, and the rest of 65 for testing your final model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE8DPEbyzcdp"
      },
      "source": [
        "## Imaging data\n",
        "Let's check out the imaging data that is available for each subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JiGIO5bAzcdq"
      },
      "outputs": [],
      "source": [
        "file = './data/brain_age/images/sub-CC110033_T1w_unbiased.nii.gz'\n",
        "\n",
        "image = nib.load(file).get_fdata()\n",
        "\n",
        "f, axarr = plt.subplots(1, 3)\n",
        "H, W, D = image.shape\n",
        "axarr[0].imshow(np.flip(image[H // 2, :, :].T, axis=0), cmap='gray')\n",
        "axarr[1].imshow(np.flip(image[:, W // 2, :].T, axis=0), cmap='gray')\n",
        "axarr[2].imshow(image[:, :, D // 2].T, cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q3nVfarhzcds"
      },
      "source": [
        "## Data loading and visualization\n",
        "\n",
        "Let's first load all the data and make a tranin/val/test split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FERY0SaUzcdt"
      },
      "outputs": [],
      "source": [
        "paths = sorted(glob.glob('data/brain_age/segs_refs/*'))\n",
        "filenames, segmentations = load_segmentations(paths)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(10282022)\n",
        "\n",
        "all_keys = np.asarray(range(len(filenames)))\n",
        "ratio_test = int(0.1 * len(all_keys))  # 10% val; 10% test\n",
        "val_keys = np.random.choice(all_keys, 2 * ratio_test, replace=False)\n",
        "test_keys = np.random.choice(val_keys, ratio_test, replace=False)\n",
        "\n",
        "train_files, val_files, test_files = [], [], []\n",
        "segmentations_train, segmentations_val, segmentations_test =  [],  [], [] \n",
        "for scan_id in tqdm(all_keys):\n",
        "  scan = f'data/brain_age/images/sub-{filenames[scan_id]}_T1w_unbiased.nii.gz'\n",
        "  seg = segmentations[scan_id]\n",
        "  if scan_id in test_keys:\n",
        "      test_files.append(scan)\n",
        "      segmentations_test.append(seg)\n",
        "  elif scan_id in val_keys:\n",
        "      val_files.append(scan)\n",
        "      segmentations_val.append(seg)\n",
        "  else:\n",
        "      train_files.append(scan)\n",
        "      segmentations_train.append(seg)\n",
        "print(f'{len(train_files)} train files')\n",
        "print(f'{len(val_files)} val files')\n",
        "print(f'{len(test_files)} test files')"
      ],
      "metadata": {
        "id": "TJ_TcBL3aRTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's visualize one validations sample "
      ],
      "metadata": {
        "id": "uhS5vDgtaSgT"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zn-msf1nzcdt"
      },
      "outputs": [],
      "source": [
        "im = load_nii(val_files[0])\n",
        "plot_segmentations(im, segmentations_val[0], i=47)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 1: Evaluation: TASK"
      ],
      "metadata": {
        "id": "KMLq31e0wKZ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We first have to define how good our predicted segmentations are. Implement the evaluation function below. "
      ],
      "metadata": {
        "id": "gtb6XonTwR-J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# The Dice similarity coefficient is widely used for evaluating image segmentation alogrithms and measures the intersection over union of predicted segmentations to ground truth\n",
        "# Implement a method that computes the patient-wise Dice score (mean and std) for the test dataset\n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "def Dice(predictions, gt):\n",
        "  mean, std = None, None  \n",
        "  return mean, std\n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "F97e34WkxGwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r6qZTrXRzcdr"
      },
      "source": [
        "# Task 2: Unsupervised segmentation "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LMngxM03zcds"
      },
      "source": [
        "The first approach aims to segment the brain tissues, including grey matter (GM), white matter (WM), cerebrospinal fluid (CSF), and background using unsupervised classical machine learning techniques.\n",
        "\n",
        "Different unsupervised techniques to leverage the different intensity profile of the tissues should be explored. "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "slice_id = 0\n",
        "im_ = load_nii(val_files[slice_id])[:,:,47].flatten()\n",
        "seg_ = segmentations_val[slice_id][:,:,47].flatten()\n",
        "\n",
        "fig, axes = plt.subplots(1, 2, figsize=(12, 4), sharey=False)\n",
        "fig.suptitle('Intensity Density Plot')\n",
        "\n",
        "sns.kdeplot(im_, ax=axes[0], fill=True)\n",
        "axes[0].set_title('Input')\n",
        "\n",
        "sns.kdeplot(im_[np.argwhere(seg_ == 0)][:, 0], ax=axes[1], fill=True, color='#85929E', label='Background', legend=True)\n",
        "sns.kdeplot(im_[np.argwhere(seg_ == 1)][:, 0], ax=axes[1], fill=True, color='#9FE2BF', label='CSF', legend=True)\n",
        "sns.kdeplot(im_[np.argwhere(seg_ == 3)][:, 0], ax=axes[1], fill=True, color='#CD5C5C', label='WM', legend=True)\n",
        "sns.kdeplot(im_[np.argwhere(seg_ == 2)][:, 0], ax=axes[1], fill=True, color='#6495ED', label='GM', legend=True)\n",
        "axes[1].set_ylim(0, 0.05)\n",
        "axes[1].set_title('Ground truth')\n",
        "plt.legend(loc=9, labels=['Background', 'CSF', 'WM', 'GM'])"
      ],
      "metadata": {
        "id": "xl2tkUKmLCXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Unsupervised Learning: TASK\n",
        "\n",
        "Here, you should experiment with different *classical* unsupervised machine learning methods, e.g., clustering, density estimation, etc... (at least two different methods). Hint: sklearn has implementations of unsupervised methods\n",
         "\n",
        "HINT: You can predict the different classes of intensities even without any training!\n",
         "\n",
        "HINT: You can evaluate every volume slice-by-slice if the whole volume does not fit in the memory."
      ],
      "metadata": {
        "id": "tOYC53CCRhUB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q1: What is the most intuitve segmentation approach? (based on the intensity density plot of the input)\n",
        "Hint: What distibution best describes the intensity density plot above? "
      ],
      "metadata": {
        "id": "1D6I1XQkilUD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q2: Evaluate the Dice scores (separately for every tissue type) for the whole test set using method 1. What results do you get? "
      ],
      "metadata": {
        "id": "mCTTP5HziRHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised method 1 \n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "pred_seg_1 = None\n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "kA_X8KPLgrSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the obtained results for volume 0 and axial slice 47 of the validations set (density estimations)\n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "sns_plot_1 = None \n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "-3uoZjMAyK5g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q3: Evaluate the Dice scores (separately for every tissue type) for the whole test set using method 2. What results do you get? "
      ],
      "metadata": {
        "id": "kDTA9E2xy4oy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unsupervised method 2 \n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "pred_seg_2 = None\n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "sgjU-EUuhEdF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the obtained results for volume 0 and axial slice 47 of the validations set (density estimations)\n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "sns_plot_2 = None \n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "5BIr_bGgy0FS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q4: Which approach worked better? Why? "
      ],
      "metadata": {
        "id": "s8JEIkPkz8HY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Task 3: Deep supervised segmentation"
      ],
      "metadata": {
        "id": "fsoCW_Pp0KEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning (DL) methods achieve state-of-the-art results in many (medical) image analyzis applications, including segmentation. Here, you will implement and train a DL method to segment CSF, WM, GM, and background in brain MRI."
      ],
      "metadata": {
        "id": "m5hbpwC40RsV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, let's have a look at the individual channels of the segmentations. "
      ],
      "metadata": {
        "id": "rCcvkvFe03pW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "im = load_nii(val_files[0])\n",
        "csf, wm, gm, background = np.zeros(im.shape), np.zeros(im.shape), np.zeros(im.shape), np.zeros(im.shape)\n",
        "csf[segmentations_val[0]==1] = 1\n",
        "wm[segmentations_val[0]==2] = 1\n",
        "gm[segmentations_val[0]==3] = 1\n",
        "background[segmentations_val[0]==0]=1\n",
        "elements = [im, csf, wm, gm, background] \n",
        "titles = ['Input', 'CSF', 'WM', 'GM', 'Background']\n",
        "diffp, axarr = plt.subplots(1, len(elements), gridspec_kw={'wspace': 0, 'hspace': 0})\n",
        "diffp.set_size_inches(len(elements) * 4, 4)\n",
        "for idx_arr in range(len(axarr)):\n",
        "    axarr[idx_arr].axis('off')\n",
        "    el = np.squeeze(elements[idx_arr][:,:,47])\n",
        "    axarr[idx_arr].imshow(el.T, cmap='gray')\n",
        "    axarr[idx_arr].set_title(titles[idx_arr])"
      ],
      "metadata": {
        "id": "dLS5T1ZJ1yTo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## DL-based segmentation: TASK"
      ],
      "metadata": {
        "id": "rVZ3Xfdx19Sc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define and train a neural network for segmentation below (use the train, val, and test splits defined above)\n",
        "\n",
        "HINT: You can use pre-defined models, e.g., from torchvision, but train them from scratch (no pre-training)"
      ],
      "metadata": {
        "id": "FTwYzoUO2d7s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define and train a neural network for segmentation\n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "pred_seg_3 = None \n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "45St-8Pw2O6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q5: Evaluate the Dice scores (separately for every tissue type) for the whole test set.  What results do you get? "
      ],
      "metadata": {
        "id": "-w-Ra366W3nT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize individual segmentation channels for axial slice 47 of all three approaches and the ground truth in a similar style as above\n",
        "# --------------------------- ADD YOUR CODE HERE ------------------------------\n",
        "plt_seg_1 = None\n",
        "plt_seg_2 = None\n",
        "plt_seg_3 = None\n",
        "plt_gt = None  \n",
        "# ----------------------------------- END -------------------------------------"
      ],
      "metadata": {
        "id": "d7BqBfl93fCx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q6: Which of the three aproaches above (classical and DL) obtains better results? Why? "
      ],
      "metadata": {
        "id": "0M8zoCj13xpA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### QUESTION Q7: What extra-information in the volumes is used by the DL models compared to the unsupervised approaches in Task 2? Why is it helpful? "
      ],
      "metadata": {
        "id": "wy4Khjb335Kv"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Zzj7LviN6Jcm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "59efc9589e5e0a10197249f838db0eb26aa8a323367b3d188d3e2ee96ab5bb66"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
